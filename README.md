# Pipeline de DataOps para HR Analytics - Da Qualidade de Dados Ã  FundaÃ§Ã£o para MLOps

## ğŸ” VisÃ£o Geral

Este repositÃ³rio apresenta a construÃ§Ã£o de um **pipeline completo de DataOps** para prÃ©-processamento, validaÃ§Ã£o e preparaÃ§Ã£o de dados, aplicado a um contexto estratÃ©gico de **Recursos Humanos e avaliaÃ§Ã£o psicotÃ©cnica**.

O projeto tem como foco **qualidade de dados, rastreabilidade e reprodutibilidade**, servindo como **fundaÃ§Ã£o confiÃ¡vel** para todo o ciclo analÃ­tico: desde anÃ¡lises descritivas atÃ© modelagem preditiva e prescritiva.

> **PrincÃ­pio-chave:** sem DataOps, nÃ£o existe MLOps.

## ğŸ“Œ Problema de NegÃ³cio

OrganizaÃ§Ãµes frequentemente enfrentam **problemas estruturais de qualidade de dados** em bases de RH que comprometem anÃ¡lises confiÃ¡veis:
- Valores ausentes e registros duplicados
- Valores invÃ¡lidos (ex.: salÃ¡rio negativo)
- AusÃªncia de validaÃ§Ã£o de schema
- Impacto direto em KPIs e decisÃµes estratÃ©gicas

**Pergunta central:** *Como transformar dados brutos e inconsistentes em um ativo analÃ­tico confiÃ¡vel, escalÃ¡vel e pronto para produÃ§Ã£o?*

## ğŸ¯ Objetivos

- Construir um **pipeline de DataOps** para validaÃ§Ã£o e tratamento de dados
- Garantir **qualidade, consistÃªncia e rastreabilidade**
- Preparar datasets para anÃ¡lises e modelagem preditiva
- Entregar **artefatos de dados prontos para produÃ§Ã£o**

## ğŸ›  Tecnologias Utilizadas

- **Python** (Pandas, NumPy)
- **Jupyter Notebook** para anÃ¡lise exploratÃ³ria
- **Pipeline modular** com separaÃ§Ã£o raw/processed
- **PrÃ¡ticas de versionamento** e qualidade de dados
- **CompatÃ­vel com MLOps** (MLflow, Feature Stores, CI/CD)

## ğŸ“ Estrutura do Projeto

```
data/
â”œâ”€â”€ raw/           # Dados brutos originais
â””â”€â”€ processed/     # Dados validados e versionados

src/               # Pipeline modular e reutilizÃ¡vel
artifacts/         # Ativos prontos para modelagem
notebooks/         # AnÃ¡lise exploratÃ³ria e documentaÃ§Ã£o
```

## ğŸ” Abordagem MetodolÃ³gica

1. **AnÃ¡lise ExploratÃ³ria de Dados (EDA)**
   - InspeÃ§Ã£o de distribuiÃ§Ãµes e detecÃ§Ã£o de inconsistÃªncias
   - AvaliaÃ§Ã£o de impacto nos indicadores de negÃ³cio

2. **ValidaÃ§Ã£o de Qualidade de Dados**
   - DefiniÃ§Ã£o de data quality gates explÃ­citos
   - ValidaÃ§Ã£o de schema, faixas de valores e unicidade

3. **Limpeza e Tratamento**
   - CorreÃ§Ã£o de valores invÃ¡lidos
   - EstratÃ©gias de imputaÃ§Ã£o contextual
   - DeduplicaÃ§Ã£o de registros

4. **PreparaÃ§Ã£o para Modelagem**
   - Dataset final estruturado e versionado
   - Features prontas para consumo por modelos

## ğŸ“¦ EntregÃ¡veis

- `data/processed/dataset_clean_v1.csv` - dataset validado e pronto para uso
- Pipeline de prÃ©-processamento reprodutÃ­vel
- RelatÃ³rio analÃ­tico com problemas identificados e decisÃµes tomadas
- Modelo empacotado como serviÃ§o (com MLflow e FastAPI)

## ğŸš€ Model Delivery & Consumption

O modelo Ã© entregue como **serviÃ§o reutilizÃ¡vel e pronto para produÃ§Ã£o**:

- **Empacotamento**: Versionado como artefato (`models/latest.joblib`)
- **Registro**: MLflow com parÃ¢metros, mÃ©tricas e artefatos
- **Consumo**: API REST via FastAPI com endpoints:
  - `GET /health` - verificaÃ§Ã£o de status
  - `POST /predict` - inferÃªncia online

## ğŸ“Š Insights e ConclusÃµes

- Dados de RH sem validaÃ§Ã£o levam a **decisÃµes enviesadas**
- **Qualidade de dados Ã© prÃ©-requisito** para modelos preditivos confiÃ¡veis
- DataOps viabiliza MLOps â€” nÃ£o o contrÃ¡rio
- Pipeline estruturado para escalabilidade e produÃ§Ã£o

## ğŸ”§ Como Usar

1. Clone o repositÃ³rio
2. Instale as dependÃªncias: `pip install -r requirements.txt`
3. Execute a anÃ¡lise exploratÃ³ria nos notebooks/
4. Utilize o pipeline modular em src/ para processamento
5. Consulte a documentaÃ§Ã£o para deploy do modelo como API

---

**Status do Projeto**: âœ… ConcluÃ­do e pronto para produÃ§Ã£o  
